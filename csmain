#!/usr/bin/python3
import os
import json
import cloudscheduler.jobmanager
import cloudscheduler.cloudmanager
import cloudscheduler.config as csconfig

from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy.ext.automap import automap_base


CLOUDRESOURCES = {}

def main():
    jobmanager = cloudscheduler.jobmanager.JobManager()
    cm = cloudscheduler.cloudmanager.CloudManager(name='mhp', resource_file='/home/mhp/cloudscheduler/cloudresources.yaml')
    cm.setup()
    CLOUDRESOURCES[cm.name] = cm
    print(CLOUDRESOURCES['mhp'])

    while(True):
        pass
        # basic scheduling: fifo w/ condor_prioity
        #for each of the CLOUDRESOURCES:
        for user in CLOUDRESOURCES:
            print(user)
            # get the idle_jobs for the user of current resources
            # sort jobs of that user by priority
            Base = automap_base()
            engine = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
            Base.prepare(engine, reflect=True)
            Job = Base.classes.condor_jobs # table name?
            session = Session(engine)
            idle_jobs = session.query(Job).filter(Job.User.contains(user), Job.JobStatus == 1).order_by(Job.JobPrio) 
            # Not sure I like the contains since it could get other things, but the DB stores the user as user@hostname
            # so would either need to build that in or ignore, but with multiple schedd the hostname may not be of interest much? depends on how schedds are related to collectors
            print(idle_jobs[0])
            print(CLOUDRESOURCES[user].clouds.keys())
            #CLOUDRESOURCES[user].clouds['beaver'].vm_create(idle_jobs[0])
            #for job in idle_jobs:
                #print(job)
                #print(job.__dict__)
        # based on idle jobs determine if current resource allocation should change/increase/decrease based on the highest priority job
        # make needed changes: retire machines/terminate retired ones/check on states and remove from system
        # boot vms if space available
            #if CLOUDRESOURCES[user].check_for_availability(idle_jobs[0]):
                #CLOUDRESOURCES[user].create_vm(idle_jobs[0])

        break

    import time
    time.sleep(15)

    # Remove all the VMs for the moment
    for user in CLOUDRESOURCES:
        for cloud in CLOUDRESOURCES[user].clouds:
            for vm in list(CLOUDRESOURCES[user].clouds[cloud].vms.keys()):
                CLOUDRESOURCES[user].clouds[cloud].vm_destroy(CLOUDRESOURCES[user].clouds[cloud].vms[vm])
# maintain a dict of cloudmanager objects
# initially load up the default one
# when new user detected check for a cloud resource file and load / add to dict key user name

def add_user_cloud(user, user_resource_file=None):
    if not user_resource_file:
        homedir = os.path.expanduser(''.join['~', user])
        user_resource_file = ''.join([homedir, '/.cloudscheduler/cloudresources.yaml'])
    cmuser = cloudscheduler.cloudmanager.CloudManager(name=user, resource_file=user_resource_file)
    cmuser.setup()
    CLOUDRESOURCES[cmuser.name] = cmuser

print("csmain")
main()
