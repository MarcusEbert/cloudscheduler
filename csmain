#!/usr/bin/python3
import os
import json
import cloudscheduler.jobmanager
import cloudscheduler.cloudmanager
import cloudscheduler.config as csconfig

from lib.schema import view_groups_of_idle_jobs
from lib.schema import view_resources_matching_idle_jobs

from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy.ext.automap import automap_base


CLOUDRESOURCES = {}

def main():

    while(True):
        # basic scheduling: fifo w/ condor_prioity

        Base0 = automap_base()
        engine0 = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
        Base0.prepare(engine0, reflect=True)
        CSGroups = Base0.classes.csv2_groups
        session0 = Session(engine0)
        # Get all the current csv2_groups
        csv2groups = session0.query(CSGroups)
        #print(type(csv2groups))
        #print(type(csv2groups[0]),csv2groups[0])
        for csgroup in csv2groups:
            print(csgroup.group_name)

            # Setup the resources for group and sort out their group and cloud specific yamls
            Base = automap_base()
            engine = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
            Base.prepare(engine, reflect=True)
            session = Session(engine)

            Resources = Base.classes.csv2_group_resources
            group_resources = session.query(Resources).filter(Resources.group_name == csgroup.group_name)
            Group_Yaml = Base.classes.csv2_group_yaml
            group_yamls = session.query(Group_Yaml).filter(Group_Yaml.group_name == csgroup.group_name)
            group_yaml_list = []
            for yam in group_yamls:
                group_yaml_list.append((yam.yaml_name, yam.yaml, yam.mime_type))
            cm_group = cloudscheduler.cloudmanager.CloudManager(name=csgroup.group_name, group_resources=group_resources, group_yamls=group_yaml_list)
            cm_group.setup()
            # At this point I should have a valid set of all the group and cloud specific yaml to use
            # it will still need to be combined with the job yaml - done now in the basecloud prepare_userdata function


            # Booting up new VMs to fill in any free space on available clouds related to idle queued jobs
            # Get the idle jobs for the current group
            idle_jobs_for_group = session.query(view_groups_of_idle_jobs).filter(
                view_groups_of_idle_jobs.c.group_name == csgroup.group_name).order_by(
                view_groups_of_idle_jobs.c.job_priority)

            for idle_job in idle_jobs_for_group:

                print(idle_job.flavors) # flavors is generated line based on which flavor is the best fit and which clouds have available resources
                    # the format is "Group:Cloud:Flavor, Group:Cloud:Flavor" will need to split and use to filter in resources_matching
                job_count = idle_job.count # number of jobs with identical request
                flavor_list = [x.strip() for x in idle_job.flavors.split(',')]
                target_cloud_list = [x.strip() for x in idle_job.target_clouds.split(',')]
                for tri in flavor_list:
                    (group, cloud, flavor) = tri.split(':')
                    clouds_matching = session.query(view_resources_matching_idle_jobs).filter(
                        view_resources_matching_idle_jobs.c.flavor == tri,
                        view_resources_matching_idle_jobs.c.cloud_name in target_cloud_list)
                    for cloud_match in clouds_matching:
                        #print(cloud_match.flavor_id) # id of flavor to avoid naming conflicts (may not need but doesn't hurt)
                        #print(cloud_match.flavor_name) # alternative to the id
                        #print(cloud_match.cloud_name) # can use this if i've constructed the resources previously.
                        #print(cloud_match.flavor_slots)  # how many of that flavor can be booted
                        # how many VMs should I try to boot? lets just go for max we can for now until we add config for limits
                        num_vms_to_boot = job_count if job_count <= cloud_match.flavor_slots else cloud_match.flavor_slots
                        cm_group.clouds[cloud_match.cloud_name].vm_create(group_yaml_list=cm_group.group_yamls,
                                                                          num=num_vms_to_boot,flavor=cloud_match.flavor_name,job=idle_job)
                        job_count -= num_vms_to_boot



        break # will need to take this out and put in an actual stopping condition.

    import time
    time.sleep(15)

    # Remove all the VMs for the moment
    for user in CLOUDRESOURCES:
        for cloud in CLOUDRESOURCES[user].clouds:
            for vm in list(CLOUDRESOURCES[user].clouds[cloud].vms.keys()):
                CLOUDRESOURCES[user].clouds[cloud].vm_destroy(CLOUDRESOURCES[user].clouds[cloud].vms[vm])
# maintain a dict of cloudmanager objects
# initially load up the default one
# when new user detected check for a cloud resource file and load / add to dict key user name

# should re-adapt this to deal with adding group from DB and splitting code into functions instead of all inline
def add_user_cloud(user, user_resource_file=None):
    if not user_resource_file:
        homedir = os.path.expanduser(''.join['~', user])
        user_resource_file = ''.join([homedir, '/.cloudscheduler/cloudresources.yaml'])
    cmuser = cloudscheduler.cloudmanager.CloudManager(name=user, resource_file=user_resource_file)
    cmuser.setup()
    CLOUDRESOURCES[cmuser.name] = cmuser

print("csmain")
main()
