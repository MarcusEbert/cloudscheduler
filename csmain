#!/usr/bin/python3

import copy
import json
import math
import time
import logging
from collections import defaultdict

import cloudscheduler.jobmanager
import cloudscheduler.cloudmanager

from lib.schema import view_vms
from lib.schema import view_groups_of_idle_jobs
from lib.schema import view_available_resources
from lib.schema import view_condor_jobs_group_defaults_applied
from lib.schema import view_clouds
from lib.schema import view_metadata_collation_json

from lib.db_config import Config

from sqlalchemy import exists
from sqlalchemy.sql import select


def main():
    """
    main function.
    """

    config = Config('/etc/cloudscheduler/cloudscheduler.yaml', 'csmain')
    if not config:
        print("Problem loading config file.")
    logging.basicConfig(level=config.log_level,
                        format="%(asctime)s - %(processName)-16s - %(levelname)s - %(message)s")
    log = logging.getLogger(__name__)
    #config.db_open()

    while(True):
        # basic scheduling: fifo w/ condor_prioity
        CSGroups = config.db_map.classes.csv2_groups
        config.db_open()
        # Get all the current csv2_groups
        csv2groups = config.db_session.query(CSGroups)
        #csv2groups = session0.query(CSGroups)
        #logging.debug(type(csv2groups))
        #log.debug(type(csv2groups[0]),csv2groups[0])

        # Get the metadata for groups as json selects with mime_types pre-sorted
        # metadata format: { group : { cloud: [(yaml select, mime_type), (yaml select, mime_type) ] } }
        try:
            metadata = json.loads(config.db_connection.execute(select([view_metadata_collation_json])).fetchone().group_metadata)
        except AttributeError as ae:
            log.exception("Probably loading metadata, is there no metadata?")


        for csgroup in csv2groups:
            log.debug("Dealing with current group: %s", csgroup.group_name)
            if csgroup.group_name in metadata.keys():
                pass
            else:
                log.debug("No metadata/yamls found for group: %s this may cause problem with VMs registering to condor.",
                          csgroup.group_name)

            # Setup the resources for group and sort out their group and cloud specific yamls
            group_resources = config.db_session.query(view_clouds).filter(view_clouds.c.group_name == csgroup.group_name,
                                                                         view_clouds.c.enabled == 1)
            Group_metadata = config.db_map.classes.csv2_group_metadata
            group_yamls = config.db_session.query(Group_metadata).filter(Group_metadata.group_name == csgroup.group_name,
                                                           Group_metadata.enabled == 1)
            group_yaml_list = []
            for yam in group_yamls:
                group_yaml_list.append([yam.metadata_name, yam.metadata, yam.mime_type, yam.priority])
            cm_group = cloudscheduler.cloudmanager.CloudManager(name=csgroup.group_name, group_resources=group_resources,
                                                                group_yamls=group_yaml_list,
                                                                metadata=metadata[csgroup.group_name] if csgroup.group_name in metadata.keys() else None)
            cm_group.setup()
            # At this point I should have a valid set of all the group and cloud specific yaml to use
            # it will still need to be combined with the job yaml - done now in the basecloud prepare_userdata function

            # Clean up the idle machines and unregistered VMs.
            # Should return or build up some meta data about what's booting/running
            # To use that info when scheduling idle jobs
            # ie just booted machines should register soon so don't boot more VMs for a small number of jobs.
            #verify_idle_jobs(csgroup.group_name)
            check_idle_time(csgroup.group_name, config)
            check_idle_time_unset(csgroup.group_name, config)
            idle_machines = check_idle_machines(csgroup.group_name, config)
            new_vms = check_unregistered_machines(csgroup.group_name,config)
            current_flavors = count_cloud_flavors(csgroup.group_name, config)
            log.debug("Group: %s Current flavors: %s", csgroup.group_name, current_flavors)
            config.db_open()
            # Booting up new VMs to fill in any free space on available clouds related to idle queued jobs
            # Get the idle jobs for the current group
            idle_jobs_for_group = config.db_session.query(view_groups_of_idle_jobs).filter(
                view_groups_of_idle_jobs.c.group_name == csgroup.group_name).order_by(
                view_groups_of_idle_jobs.c.job_priority)
            log.debug('---------------got idle jobs--------------')
            cloud_booted_on = set()  #  Setting this up here now so I can check it and skip over things I boot on due to available slots info will be wrong
            for idle_job in idle_jobs_for_group:
                if idle_job.idle == 0:
                    continue
                log.debug("Info for current job: Group: %s, Target: %s, User: %s, Flavors: %s",idle_job.group_name, idle_job.target_clouds,
                          idle_job.user, idle_job.flavors)
                # flavors is generated line based on which flavor is the best fit and which clouds have available resources
                # the format is "Group:Cloud:Flavor, Group:Cloud:Flavor" will need to split and use to filter in resources_matching
                
                if idle_job.flavors:
                    flavor_list = [x.strip() for x in idle_job.flavors.split(',')]
                else:
                    continue
                if idle_job.target_clouds:
                    target_cloud_list = [x.strip() for x in idle_job.target_clouds.split(',')]
                    # Issue #36
                    if not set(target_cloud_list).intersection(set(cm_group.clouds.keys())):
                        log.warning("No Target Cloud found in currently available or enabled clouds. for jobs: %s", idle_job)
                        continue
                        # TODO Flag job to hold it? these jobs are grouped though, and IDs aren't listed in view, makes it harder to pinpoint them.
                        # Either need to query them somehow, or see if it's possible for that view to list/include all the IDs in that set. Ask Colin

                else:
                    target_cloud_list = []

                # Get All the possible matching clouds
                if target_cloud_list:
                    clouds_matching = config.db_session.query(view_available_resources).filter(
                        view_available_resources.c.flavor.in_(flavor_list),
                        view_available_resources.c.cloud_name.in_(target_cloud_list))
                else:
                    clouds_matching = config.db_session.query(view_available_resources).filter(
                        view_available_resources.c.flavor.in_(flavor_list))
                num_jobs_per_flavor_possible = {}
                for cloud_match in clouds_matching:
                    cpu = cloud_match.flavor_cores / idle_job.request_cpus_min
                    ram = cloud_match.flavor_ram / idle_job.request_ram_min
                    disk = cloud_match.flavor_disk / idle_job.request_disk_min if idle_job.request_disk_min else None
                    jobs_possible = int(min([cpu,ram,disk])) if disk else int(min([cpu, ram]))
                    if jobs_possible < 1:
                        jobs_possible = 1
                    num_jobs_per_flavor_possible[cloud_match.flavor] = jobs_possible
                log.debug("num jobs per flavor: %s", num_jobs_per_flavor_possible)
                # Now have the amount of jobs that can run on each option
                # Next get all the VMs for this group with their flavor info - actually could be done outside of loop and re-use it
                # Need a structure of the groups VMs accessible by the cloud_name and with a count of the flavor
                # ie vms[cloud-name][flavor] = 6
                runnable_job_count = 0
                for flavor in num_jobs_per_flavor_possible.keys():
                    (cloud_name, flavor_name) = flavor.split(':')
                    runnable_job_count += num_jobs_per_flavor_possible[flavor] * current_flavors[cloud_name][flavor_name]
                log.debug("Runnable_job_count before: %s", runnable_job_count)
                runnable_job_count -= idle_job.running  # Subtract the already running jobs
                runnable_job_count -= idle_job.idle  # subtract the idle jobs in case there's unregistered, unmatched, or poller delay
                log.debug("Runnable_job_count after: %s", runnable_job_count)
                log.debug("Running: %s, Idle: %s", idle_job.running, idle_job.idle)
                if runnable_job_count < 0: # Need more VMs - try to boot stuff - does this really need to be <= or just < ??? - trying it as < only
                    log.debug("flavor list: %s", flavor_list)
                    if target_cloud_list:
                        clouds_matching_new = config.db_session.query(view_available_resources).filter(
                            view_available_resources.c.flavor.in_(flavor_list),
                            view_available_resources.c.cloud_name.in_(target_cloud_list))
                    else:
                        clouds_matching_new = config.db_session.query(view_available_resources).filter(
                            view_available_resources.c.flavor.in_(flavor_list))

                    for cloud in clouds_matching_new:
                        if cloud.cloud_name in cloud_booted_on:
                            continue
                        log.debug("Taking a look at booting on: %s", cloud.cloud_name)
                        log.debug("Using Flavor: %s", cloud.flavor)
                        log.debug("num jobs per flavor: %s, flavor slots: %s", num_jobs_per_flavor_possible, cloud.flavor_slots)
                        # Need to redo this calculation for each cloud / flavor because it may change
                        num_vms_to_boot = abs(runnable_job_count) / num_jobs_per_flavor_possible[cloud.flavor]
                        log.debug("Initially try boot: %s based on possible per flavor", num_vms_to_boot)
                        # This is the total wanted, but cloud may not be able to handle that request
                        num_vms_to_boot = num_vms_to_boot if num_vms_to_boot <= cloud.flavor_slots else cloud.flavor_slots
                        num_vms_to_boot = math.ceil(num_vms_to_boot)
                        log.debug("Try to boot: %s after checking flavor slots.", num_vms_to_boot)
                        # Throttle amount of VMs to boot in one shot - should this be per cloud?
                        if num_vms_to_boot > config.max_start_vm_cloud:
                            num_vms_to_boot = config.max_start_vm_cloud
                            log.debug("Adjusting for max_boot, will only boot: %s vms.", num_vms_to_boot)
                        log.debug("Would like to boot %s VMs on %s", num_vms_to_boot, cloud.cloud_name)
                        try:
                            usertmp = idle_job.user.split('@')[0]
                        except:
                            usertmp = idle_job.user
                        template_dict = {'cs_user': usertmp,
                                         'cs_group_name': csgroup.group_name,
                                         'cs_condor_host': csgroup.condor_central_manager}
                        log.debug(template_dict)
                        try:
                            if cm_group.clouds[cloud.cloud_name].enabled:
                                use_image = None
                                if idle_job.image:
                                    use_image = None
                                elif cloud.default_image:
                                    use_image = cloud.default_image
                                else:
                                    pass

                                cm_group.clouds[cloud.cloud_name]\
                                    .vm_create(group_yaml_list=copy.deepcopy(cm_group.group_yamls),
                                               num=int(num_vms_to_boot),
                                               flavor=cloud.flavor,  #cloud_match.flavor_name, # pass 'tri' instead so it keeps the group:cloud:flavor info?
                                               job=idle_job,
                                               template_dict=template_dict,
                                               image = use_image)
                                runnable_job_count += num_vms_to_boot * num_jobs_per_flavor_possible[cloud.flavor]
                                log.debug('done booting on cloud %s', cloud.cloud_name)
                                cloud_booted_on.add(cloud.cloud_name)
                            if runnable_job_count < 0:  # Still need more
                                log.debug("Runnable total still negative after booting VMs, try to boot more on another cloud if possible.")
                                continue
                            else:
                                log.debug("Seem to have booted enough for this job for now.")
                                break

                        except Exception as ex:
                            # lets try to disable or dump this cloud for now
                            log.exception("Disable cloud %s due to exception(later).", cloud.cloud_name)
                            #cm_group.clouds[cloud_match.cloud_name].enabled = False
                            # TODO Need logic for re-enable before stopping things and forgetting about them.
                    else:
                        log.debug("Hit the end of clouds_matching_new, anything boot or nothing?")
                else:  # We have enough, wait for things to register
                    log.debug("Seem to have enough VMs for the number of idle jobs.")
                    log.debug("Runnable count: %s", runnable_job_count)
                    continue
        time.sleep(15)  # delay between groups


            # Done Trying to schedule idle jobs on free resources.
            # Other tasks the scheduling loop needs to handle for a group?
            # Will need to see about freeing space for higher priority jobs that are not running.

            # Repeat for next group
        #break # will need to take this out and put in an actual stopping condition.

def verify_idle_jobs(group, config):
    """ Check the view for idle jobs and make sure it has all the required fields
    Hold jobs that fail the tests."""
    log = logging.getLogger(__name__)
    log.debug("Verify jobs for group: %s", group)

    config.db_open()
    idle_jobs_for_group = config.db_session.query(view_condor_jobs_group_defaults_applied).filter(
        view_condor_jobs_group_defaults_applied.c.group_name == group,
        view_condor_jobs_group_defaults_applied.c.job_status == 1)
    bad_jobs = {}
    for job in idle_jobs_for_group:
        if not job.image:
            bad_jobs[job.global_job_id] = "Missing Image"
    condor_jobs = config.db_map.classes.condor_jobs
    jobs = config.db_session.query(condor_jobs).filter(condor_jobs.global_job_id.in_(bad_jobs.keys()))
    for job in jobs:
        try:
            job.hold_job_reason = bad_jobs[job.global_job_id]
        except KeyError:
            continue
    try:
        config.db_close()
    except Exception as ex:
        log.exception(ex)
    log.debug("Done Verify jobs.")
    return


def count_cloud_flavors(group, config):
    """Query the VMs for group and arrange into a dictionary format
    of dict[cloud_name][flavor] = count of that flavor
    """
    log = logging.getLogger(__name__)
    config.db_open()
    group_vms = config.db_session.query(view_vms).filter(view_vms.c.group_name == group, view_vms.c.foreign_vm == 0)
    vm_cloud_flavors = defaultdict(lambda: defaultdict(int))
    for vm in group_vms:
        vm_cloud_flavors[vm.cloud_name][vm.flavor_name] += 1
    log.debug("Done counting current flavors for group: %s.", group)
    try:
        config.db_close()
    except Exception as ex:
        log.exception("Problem closing connection: %s", ex)
    return vm_cloud_flavors


def check_registered_condor_machines(group, config):
    """Query the condor machines for everything belonging to the group to get idea
    of how many available resources there are for idle jobs - including brand new machines
    that are in the benchmarking state etc. and use that info to determine if more VMs are needed."""
    log = logging.getLogger(__name__)
    config.db_open()
    machines_dict = defaultdict(int)

    machines = config.db_map.classes.condor_machines
    registered_machines = config.db_session.query(machines).filter(machines.group_name == group)
    for machine in registered_machines:
        log.debug(machine)
        machines_dict[machine.flavor] += 1
    log.debug("Done checking registered machines classads: %s", group)
    try:
        config.db_close()
    except Exception as ex:
        log.exception(ex)
    return machines_dict


def check_idle_time(group, config):
    """
    Determine idle start time of machines to use with keep_alive
    :param group:
    :return:
    """
    # Query for classads that are unclaimed idle with no child slots(total_slots==1) and have no time set
    # set their time
    # query all the ones that have their time set
    # if state changed to something other than unclaimed / idle then unset time(idle_time)
    # if it has child slots unset time (idle_time)
    # if no reason to unset time then check how long it's been compared to the keep alive time
    # if keep alive exceeded set retire flags/time (retire_request_time)
    log = logging.getLogger(__name__)
    log.debug("Check Idle Machines for Keep Alive time for: %s", group)
    config.db_open()
    machines = config.db_map.classes.condor_machines
    unclaimed_idle_machines = config.db_session.query(machines).filter(machines.state == "Unclaimed",
                                                             machines.activity == "Idle",
                                                             machines.group_name == group,
                                                             machines.idle_time == None,
                                                             machines.total_slots == 1)
    for machine in unclaimed_idle_machines:
        machine.idle_time = int(time.time())
        config.db_session.merge(machine)
        log.debug("%s detected doing nothing - set idle_time.", machine.machine)
    try:
        config.db_close()
    except Exception as ex: #  sqlalchemy.exc.InternalError pymysql.err.InternalError Deadlock
        log.exception(ex)


def check_idle_time_unset(group, config):
    """
    Determine idle start time of machines to use with keep_alive
    :param group:
    :return:
    """
    # Query for classads that are unclaimed idle with no child slots(total_slots==1) and have no time set
    # set their time
    # query all the ones that have their time set
    # if state changed to something other than unclaimed / idle then unset time(idle_time)
    # if it has child slots unset time (idle_time)
    # if no reason to unset time then check how long it's been compared to the keep alive time
    # if keep alive exceeded set retire flags/time (retire_request_time)
    log = logging.getLogger(__name__)
    log.debug("Unset the idle time if needed for: %s", group)
    config.db_open()

    machines = config.db_map.classes.condor_machines
    unclaimed_idle_machines = config.db_session.query(machines).filter(machines.group_name == group,
                                                             machines.idle_time != None)
    for machine in unclaimed_idle_machines:
        if machine.total_slots != 1 or machine.state != "Unclaimed" or machine.activity != "Idle":
            log.debug("%s detected change - unset idle_time.", machine.machine)
            machine.idle_time = None
            config.db_session.merge(machine)
    try:
        config.db_close()
    except Exception as ex:
        log.exception(ex)


def check_idle_machines(group, config):
    """
    Query the condor machines and ones that are idle with no jobs requiring them
    or that have been idle an extended period of time and set the Retire flag in db for them.
    :return:
    """
    log = logging.getLogger(__name__)
    log.debug("Checking %s Idle Machines.", group)
    config.db_open()

    machines = config.db_map.classes.condor_machines
    unclaimed_idle_machines = config.db_session.query(view_vms).filter(view_vms.c.idle_time != None,
                                                             view_vms.c.group_name == group)
    machines_dict = defaultdict(int)
    idle_list = []
    for machine in unclaimed_idle_machines:
        # TODO Make sure this line is behaving as intended and not catching every machine irregardless - added a 5 min buffer for now
        if int(time.time()) - machine.idle_time > max([machine.keep_alive, 300]) and not machine.retire_request_time :
            log.debug("Setting condor off flag for machine: %s", machine.hostname)
            idle_list.append(machine.machine)  # TODO Also capture info needed to update cvs2_vms table with a 'retired' flag of sorts
        else:
            log.debug("Ignoring classad for: %s, Inactive for only %s", machine.hostname,
                      str(int(time.time()) - machine.idle_time))
            name_parts = machine.machine.split('--')
            if len(name_parts) >= 2:
                machines_dict[name_parts[1]] += 1 # key on the cloud_name part of hostname
    if idle_list:
        log.debug("setting retire_request_time on %s entries.", len(idle_list))
        update_result = config.db_session.query(machines).filter(machines.machine.in_(idle_list))
        for row in update_result:
            row.retire_request_time = int(time.time())
            config.db_session.merge(row)
        # TODO Update csv2_vms table with a retired flag on that vm
    try:
        config.db_close()
    except Exception as ex:
        log.exception(ex)
    # Return dict of cloud names with number of idle machine classads
    return machines_dict


def check_unregistered_machines(group, config):
    """Query the condor machines and cloud VMs to sort out which ones have failed to register correctly.
    and take steps to shut those down. There could be problems with shutting down machines cs isn't controlling
    so need to account for the hostnames matching the CS hostname pattern, belonging to correct group etc."""
    log = logging.getLogger(__name__)
    log.debug("Check Unregistered Machines: %s", group)
    config.db_open()

    machines = config.db_map.classes.condor_machines
    vms = config.db_map.classes.csv2_vms
    clouds = config.db_map.classes.csv2_clouds
    group_clouds = config.db_session.query(clouds).filter(clouds.group_name == group)
    unregistered_vms = config.db_session.query(view_vms).filter(view_vms.c.group_name == group, view_vms.c.foreign_vm == 0).filter(~exists().
                                                                                             where(machines.machine.contains(view_vms.c.hostname)))

    cloud_names = []
    for cloud in group_clouds:
        cloud_names.append(cloud.cloud_name)
    non_cs_vm = []
    new_vms = defaultdict(list)
    to_terminate = []
    log.debug("%s VMs that are unregistered with condor collector:", group)
    for vm in unregistered_vms:
        try:
            hostname_split = vm.hostname.split('--')
            if len(hostname_split) == 1:
                continue
            cname = hostname_split[1]
            if cname in cloud_names: # name prefix matches a valid cloud name
                if int(time.time()) - vm.last_updated > config.unregistered_machine_time_limit and not vm.terminate: # not registered after some period of time
                    to_terminate.append(vm.vmid)
                    log.debug("Set terminate flag on vm: %s", vm.hostname)
                # TODO Check the retired flag and if set terminate right away
                else:
                    log.debug("%s unregistered for: %s seconds. Terminate flag: %s", vm.hostname,
                              str(int(time.time()) - vm.last_updated), vm.terminate)
                    new_vms[vm.cloud_name].append((vm.cloud_name,vm.hostname,vm.flavor_name))
            else:
                non_cs_vm.append(vm.hostname)
        except Exception as ex:
            log.exception("Problem going through %s unregistered VMs: %s", group, ex)
    if to_terminate:
        log.debug("Setting flag in db on %s VMs. With IDs: %s", len(to_terminate), to_terminate)
        update_result = config.db_session.query(vms).filter(vms.vmid.in_(to_terminate))
        for vm in update_result:
            log.debug("Update flag on %s", vm.hostname)
            vm.terminate = 1
            config.db_session.merge(vm)
    log.debug("Done checking %s unregistered VMs.", group)
    try:
        config.db_close()
    except Exception as ex:
        log.exception(ex)
    return new_vms



main()
