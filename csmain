#!/usr/bin/python3
import os
import json
import cloudscheduler.jobmanager
import cloudscheduler.cloudmanager
import cloudscheduler.config as csconfig

from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy.ext.automap import automap_base


CLOUDRESOURCES = {}

def main():
    jobmanager = cloudscheduler.jobmanager.JobManager()
    cm = cloudscheduler.cloudmanager.CloudManager(name='mhp', resource_file='/home/mhp/cloudscheduler/cloudresources.yaml')
    cm.setup()
    CLOUDRESOURCES[cm.name] = cm
    print(CLOUDRESOURCES['mhp'])

    while(True):
        # basic scheduling: fifo w/ condor_prioity
        # Get all the current csv2_groups
        Base0 = automap_base()
        engine0 = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
        Base0.prepare(engine0, reflect=True)
        CSGroups = Base0.classes.csv2_groups
        session0 = Session(engine0)
        csv2groups = session0.query(CSGroups)
        print(type(csv2groups))
        print(type(csv2groups[0]),csv2groups[0])
        for csgroup in csv2groups:
            print(csgroup.group_name)
        #for each of the CLOUDRESOURCES
        #for user in CLOUDRESOURCES:
            #print(user)
            # get the idle_jobs for the user of current resources
            # sort jobs of that user by priority
            Base = automap_base()
            engine = create_engine("mysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
            Base.prepare(engine, reflect=True)
            session = Session(engine)

            Resources = Base.classes.csv2_group_resources
            group_resources = session.query(Resources).filter(Resources.group_name == csgroup.group_name)
            Group_Yaml = Base.classes.csv2_group_yaml
            group_yamls = session.query(Group_Yaml).filter(Group_Yaml.group_name == csgroup.group_name)
            group_yaml_list = []
            for yam in group_yamls:
                group_yaml_list.append((yam.yaml_name, yam.yaml, yam.mime_type))
            cm_group = cloudscheduler.cloudmanager.CloudManager(name=csgroup.group_name, group_resources=group_resources, group_yamls=group_yaml_list)
            cm_group.setup()
            # At this point I should have a valid set of all the group and cloud specific yaml to use
            # it will still need to be combined with the job yaml - done now in the basecloud prepare_userdata function




            # Not sure I like the contains since it could get other things, but the DB stores the user as user@hostname
            # so would either need to build that in or ignore, but with multiple schedd the hostname may not be of interest much? depends on how schedds are related to collectors
            Job = Base.classes.condor_jobs
            idle_jobs = session.query(Job).filter(Job.group_name.contains(csgroup.group_name),
                                                      Job.JobStatus == 1).order_by(Job.JobPrio)
            print(idle_jobs)



                ### Older testing code pre-db resources
            #print(CLOUDRESOURCES[user].clouds.keys())
            #CLOUDRESOURCES[user].clouds['beaver'].vm_create(idle_jobs[0])
            #for job in idle_jobs:
                #print(job)
                #print(job.__dict__)
        # based on idle jobs determine if current resource allocation should change/increase/decrease based on the highest priority job
        # make needed changes: retire machines/terminate retired ones/check on states and remove from system
        # boot vms if space available
            #if CLOUDRESOURCES[user].check_for_availability(idle_jobs[0]):
                #CLOUDRESOURCES[user].create_vm(idle_jobs[0])

        break

    import time
    time.sleep(15)

    # Remove all the VMs for the moment
    for user in CLOUDRESOURCES:
        for cloud in CLOUDRESOURCES[user].clouds:
            for vm in list(CLOUDRESOURCES[user].clouds[cloud].vms.keys()):
                CLOUDRESOURCES[user].clouds[cloud].vm_destroy(CLOUDRESOURCES[user].clouds[cloud].vms[vm])
# maintain a dict of cloudmanager objects
# initially load up the default one
# when new user detected check for a cloud resource file and load / add to dict key user name

def add_user_cloud(user, user_resource_file=None):
    if not user_resource_file:
        homedir = os.path.expanduser(''.join['~', user])
        user_resource_file = ''.join([homedir, '/.cloudscheduler/cloudresources.yaml'])
    cmuser = cloudscheduler.cloudmanager.CloudManager(name=user, resource_file=user_resource_file)
    cmuser.setup()
    CLOUDRESOURCES[cmuser.name] = cmuser

print("csmain")
main()
