#!/usr/bin/python3
import os
import logging
import jobmanager
import cloudmanager
import config as csconfig

from lib.schema import condor_jobs
from lib.schema import view_available_resources
from lib.schema import view_groups_of_idle_jobs

from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy.ext.automap import automap_base


CLOUDRESOURCES = {}

logging.basicConfig(level=logging.DEBUG,
                    format="%(asctime)s:%(levelname)s:%(name)s:%(message)s")


def main():
    """
    main function.
    """
    log = logging.getLogger(__name__)
    while(True):
        # basic scheduling: fifo w/ condor_prioity

        Base0 = automap_base()
        engine0 = create_engine("mysql+pymysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
        Base0.prepare(engine0, reflect=True)
        CSGroups = Base0.classes.csv2_groups
        session0 = Session(engine0)
        # Get all the current csv2_groups
        csv2groups = session0.query(CSGroups)
        #logging.debug(type(csv2groups))
        #log.debug(type(csv2groups[0]),csv2groups[0])
        for csgroup in csv2groups:
            if csgroup.group_name == "Testing":
                log.debug("Found testing")
                continue
            log.debug(csgroup.group_name)

            # Setup the resources for group and sort out their group and cloud specific yamls
            Base = automap_base()
            engine = create_engine("mysql+pymysql://" + csconfig.config.db_user + ":" + csconfig.config.db_password + "@" +
                     csconfig.config.db_host + ":" + str(csconfig.config.db_port) + "/" + csconfig.config.db_name)
            Base.prepare(engine, reflect=True)
            session = Session(engine)

            Resources = Base.classes.csv2_group_resources
            group_resources = session.query(Resources).filter(Resources.group_name == csgroup.group_name)
            Group_Yaml = Base.classes.csv2_group_yaml
            group_yamls = session.query(Group_Yaml).filter(Group_Yaml.group_name == csgroup.group_name)
            group_yaml_list = []
            for yam in group_yamls:
                group_yaml_list.append([yam.yaml_name, yam.yaml, yam.mime_type])
            cm_group = cloudmanager.CloudManager(name=csgroup.group_name, group_resources=group_resources, group_yamls=group_yaml_list)
            cm_group.setup()
            # At this point I should have a valid set of all the group and cloud specific yaml to use
            # it will still need to be combined with the job yaml - done now in the basecloud prepare_userdata function


            # Booting up new VMs to fill in any free space on available clouds related to idle queued jobs
            # Get the idle jobs for the current group
            #idle_jobs_for_group = session.query(view_groups_of_idle_jobs).filter(
               #view_groups_of_idle_jobs.c.group_name == csgroup.group_name).order_by(
                #view_groups_of_idle_jobs.c.job_priority)
            idle_jobs_for_group = session.query(condor_jobs).filter(
                condor_jobs.c.group_name == csgroup.group_name).order_by(
                condor_jobs.c.job_priority)
            log.debug('got idle jobs')
            for idle_job in idle_jobs_for_group:
                log.debug("In idle job loop!")

                job_count = idle_job.count # number of jobs with identical request
                log.debug(job_count)
                target_cloud_list = [x.strip() for x in idle_job.target_clouds.split(',')]
                log.debug(target_cloud_list)
                log.debug(idle_job.image)
                
                #clouds_matching = session.query(view_resources_matching_idle_jobs).filter(
                        #view_resources_matching_idle_jobs.c.flavor == tri,
                        #view_resources_matching_idle_jobs.c.cloud_name.in_(target_cloud_list)) # awkward syntax but works.
                for target_cloud in target_cloud_list:
                        #log.debug(cloud_match.flavor_id) # id of flavor to avoid naming conflicts (may not need but doesn't hurt)
                        #log.debug(cloud_match.flavor_name) # alternative to the id
                        #log.debug(cloud_match.cloud_name) # can use this if i've constructed the resources previously.
                        #log.debug(cloud_match.flavor_slots)  # how many of that flavor can be booted
                        # how many VMs should I try to boot? lets just go for max we can for now until we add config for limits
                    #num_vms_to_boot = job_count if job_count <= cloud_match.flavor_slots else cloud_match.flavor_slots
                    num_vms_to_boot = 1
                    template_dict = {'cs_user': idle_job.user,
                                     'cs_group_name': csgroup.group_name,
                                     'cs_condor_host': csgroup.condor_central_manager}
                    cm_group.clouds[target_cloud].vm_create(group_yaml_list=cm_group.group_yamls,
                                                                      num=num_vms_to_boot,
                                                                      job=idle_job,
                                                                      template_dict=template_dict)
                    log.debug('done booting on cloud %s', target_cloud)
            # Done Trying to schedule idle jobs on free resources.
            # Other tasks the scheduling loop needs to handle for a group?
            # Will need to see about freeing space for higher priority jobs that are not running.
            # Check the idle and unclaimed machines with idle time greater than configured value
                # for those machines set the flag to retire them
            # check for VMs not registered or no longer registered with condor
                # shutdown those VMs (although this may be designated to the VMPoller thingy instead



            # Repeat for next group
        break # will need to take this out and put in an actual stopping condition.

    import time
    time.sleep(10)

    # Remove all the VMs for the moment
    for user in CLOUDRESOURCES:
        for cloud in CLOUDRESOURCES[user].clouds:
            for vm in list(CLOUDRESOURCES[user].clouds[cloud].vms.keys()):
                CLOUDRESOURCES[user].clouds[cloud].vm_destroy(CLOUDRESOURCES[user].clouds[cloud].vms[vm])
# maintain a dict of cloudmanager objects
# initially load up the default one
# when new user detected check for a cloud resource file and load / add to dict key user name

# should re-adapt this to deal with adding group from DB and splitting code into functions instead of all inline
def add_user_cloud(user, user_resource_file=None):
    """

    :param user:
    :param user_resource_file:
    """
    if not user_resource_file:
        homedir = os.path.expanduser(''.join['~', user])
        user_resource_file = ''.join([homedir, '/.cloudscheduler/cloudresources.yaml'])
    cmuser = cloudscheduler.cloudmanager.CloudManager(name=user, resource_file=user_resource_file)
    cmuser.setup()
    CLOUDRESOURCES[cmuser.name] = cmuser


main()
